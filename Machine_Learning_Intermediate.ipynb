{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning-Intermediate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RfP9JReCLFV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/Sample data/melbourne_data.csv\", index_col=0)\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRIH_NeaLWcP",
        "outputId": "c66ec3e3-8623-4aa3-ccbe-52871123f75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftsEqQFxRKKU",
        "outputId": "6b39e0f9-4cdd-4bd8-da0b-4ccd1ddc997e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13580, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing values**\n",
        "\n",
        "1.Drop columns with missing values.\n",
        "\n",
        "2.Imputation (i.e)fill in the mean value along each column.\n",
        "\n",
        "3.An Extension to Imputation."
      ],
      "metadata": {
        "id": "nXn2hZF1LUzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Select target\n",
        "y = df.Price\n",
        "\n",
        "melb_predictors = data.drop(['Price'], axis=1)\n",
        "X = melb_predictors.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Dividing to training and validation subsets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n"
      ],
      "metadata": {
        "id": "JEOo-fggLvvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Function to Measure Quality of Each Approach"
      ],
      "metadata": {
        "id": "v7ykmUVTNBsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "  model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "  model.fit(X_train, y_train)\n",
        "  preds = model.predict(X_valid)\n",
        "  return mean_absolute_error(y_valid, preds)"
      ],
      "metadata": {
        "id": "beZwtDpGNDAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score from approach 1(Drop Columns with Missing Values)"
      ],
      "metadata": {
        "id": "F3hEDHirORiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get names of columns with missing values\n",
        "cols_with_missing = [col for col in X_train.columns\n",
        "                     if X_train[col].isnull().any()]\n",
        "\n",
        "# Drop columns in training and validation data\n",
        "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
        "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
        "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWL7V0CvN9b4",
        "outputId": "0c8c7f2f-285c-40a3-e400-97240bf888bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 1 (Drop columns with missing values):\n",
            "183550.22137772635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score from approach 2(Imputation)"
      ],
      "metadata": {
        "id": "xbDeNbw-PseK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns\n",
        "\n",
        "print(\"MAE from Approach 2 (Imputation):\")\n",
        "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibm3P6_PxAF",
        "outputId": "23f289a6-e180-47bc-e1b4-a0315d32e9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 2 (Imputation):\n",
            "178166.46269899711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score from approach 3(An Extension to Imputation)"
      ],
      "metadata": {
        "id": "N8lH3qoHQWoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make copy to avoid changing original data (when imputing)\n",
        "X_train_plus = X_train.copy()\n",
        "X_valid_plus = X_valid.copy()\n",
        "\n",
        "# Make new columns indicating what will be imputed\n",
        "for col in cols_with_missing:\n",
        "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
        "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
        "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_X_train_plus.columns = X_train_plus.columns\n",
        "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
        "\n",
        "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
        "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44tAzjzeQcqf",
        "outputId": "faf99fe6-e576-4d96-b754-479a3584bf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 3 (An Extension to Imputation):\n",
            "178927.503183954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION :** Approach 2 is best."
      ],
      "metadata": {
        "id": "phCzljzGQyXb"
      }
    }
  ]
}